---
title: "MATH513 Big Data and Social Network Visualization Coursework"
author: "VSK"
date: "`r Sys.Date()"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
# loading libraries
library(readr)
library(jsonlite)
library(tidytext)
library(tidyr)
library(readr)
library(dplyr)
library(lubridate)
library(stringr)
library(tidytext)
library(scales)
library(ggplot2)
```

## 2.1 Data Preparation

```{r data_preparation, echo=FALSE, message=FALSE, warning=FALSE}
setwd("C:/Users/kwsta/master_projects/Math513/CRW")
#
# list of files in a directory
# we get all the file names in the data directory (where the .txt files are stored) and store them into a list
txt_files_ls <- list.files("data")
#
# we initialize a data_frame in order to populate it
single_speech <- data_frame(speech = c(), location = c(), date = c())


# because we are lazy we use Regular expressions in order to give the locatio and dates values
location_pattern <- "[A-z]+(?=-|[A-Z])" # this pattern matches all letters until the next char is uppercase or -, so "OhioSep21_2020.txt" returns "Ohio"
day_pattern <- "[[:digit:]]+" # this pattern matches the first digits from a string until the next char is not a digit, "Ohio21_2020.txt" returns "21"
# loop in the list of files
for (i in 1: length(txt_files_ls)){
  
  file_path <- paste("data",txt_files_ls[i], sep = '/') # we create the file path using string string concatenation
  location_name <- str_extract(txt_files_ls[i], location_pattern) # we extract the location name from the file name
  
  single_day <- str_extract(txt_files_ls[i], day_pattern) # we extract the day of the speech from the file name
  speech_date <- paste("2020-09", single_day, sep = '-') # we create the speech data with string concatenation
  
  
  read_speech <- data_frame(speech = c(as.character(read_tsv(file_path, col_names=FALSE))),location = c(location_name), date = c(as_date(speech_date)))
  single_speech <- rbind(single_speech, read_speech)
                   
}
single_speech <- single_speech %>%
  arrange(date)
single_speech
```

## 2.2 Writing an R Function Showing the Change of Word Frequency Over Time

```{r format_text, echo=FALSE}
#

single_speech_split <- single_speech%>%
  select(speech,location, date) %>%   # The speech column text is actually a dataframe, 
  unnest_tokens(word, speech)   # applying unnest_tokens() to it produced an error, so had to make it character
  
# removing unuseful words
data("stop_words")
single_speech_split_clean  <- single_speech_split %>%
  anti_join(stop_words)

# there are a lot of numbers as words, need to remove them
single_speech_split_clean$word <- gsub("[[:digit:]]+",NA,  single_speech_split_clean$word)
single_speech_split_clean <- single_speech_split_clean %>%
  na.omit()
single_speech_split_clean
```

```{r graph, echo=FALSE}
#
word_frequency_table <- single_speech_split_clean %>%
  count(date, word) %>%
  group_by(date) %>%
  mutate(p = n / sum(n))
  
 
keywords <- c('biden','china','jobs','war','')

  word_frequency_table %>%
    filter(word %in% keywords) %>%
    ggplot(aes(x = date, y = n)) +
    geom_point() +
    geom_line() +
    labs(y = "Percentage of words") +
  facet_wrap(~ word) +
  scale_x_date(labels = date_format("%d %b %y"),
  limits = c(as_date("2020-09-02"),
  as_date("2020-09-24"))) +
  theme(legend.position = "none")

````