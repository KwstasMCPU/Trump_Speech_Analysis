---
title: "MATH513 Big Data and Social Network Visualization Coursework"
author: "kostas, victoria, sid"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
# loading libraries
library(readr)
library(jsonlite)
library(tidytext)
library(tidyr)
library(readr)
library(dplyr)
library(lubridate)
library(stringr)
library(tidytext)
library(scales)
library(ggplot2)
```

## 2.1 Data Preparation

```{r data_preparation, echo=FALSE, message=FALSE, warning=FALSE}
setwd("C:/Users/kwsta/master_projects/Math513/CRW")
#
# list of files in a directory
# we get all the file names in the data directory (where the .txt files are stored) and store them into a list
txt_files_ls <- list.files("data")
#
# we initialize a data_frame in order to populate it
single_speech <- data_frame(speech = c(), location = c(), date = c())


# because we are lazy we use Regular expressions in order to give the location and dates values
location_pattern <- "[A-z]+(?=-|[A-Z])" # this pattern matches all letters until the next char is uppercase or -, so "OhioSep21_2020.txt" returns "Ohio"
day_pattern <- "[[:digit:]]+" # this pattern matches the first digits from a string until the next char is not a digit, "Ohio21_2020.txt" returns "21"
# loop in the list of files
for (i in 1: length(txt_files_ls)){
  
  file_path <- paste("data",txt_files_ls[i], sep = '/') # we create the file path using string string concatenation
  location_name <- str_extract(txt_files_ls[i], location_pattern) # we extract the location name from the file name
  
  single_day <- str_extract(txt_files_ls[i], day_pattern) # we extract the day of the speech from the file name
  speech_date <- paste("2020-09", single_day, sep = '-') # we create the speech data with string concatenation
  
  
  read_speech <- data_frame(speech = c(as.character(read_tsv(file_path, col_names=FALSE))), #read_tsv creates a tibble object, so we need to convert it into a string
                            location = c(location_name), 
                            date = c(as_date(speech_date)))
  single_speech <- rbind(single_speech, read_speech)
                   
}
single_speech <- single_speech %>%
  arrange(date)
single_speech
```

\newpage

## 2.2 Writing an R Function Showing the Change of Word Frequency Over Time

```{r format_text, echo=FALSE, message=FALSE}

cleaning_spliting_speech <- function(speech_df, remove_stop_words = TRUE){
  speech_df <- speech_df %>%
  select(speech,location, date) %>%   
  unnest_tokens(word, speech)
  print(remove_stop_words)
  if(remove_stop_words) {
    data("stop_words")
    speech_df <- speech_df %>% 
      anti_join(stop_words)
  }
  speech_df
}

removing_numbers_from_speech <- function(cleaned_speech_df){
  cleaned_speech_df$word <- gsub("[[:digit:]]+",NA,   cleaned_speech_df$word)
  cleaned_speech_df %>%
    na.omit()
}
```

```{r graph, echo=FALSE, fig.height = 10,  fig.width = 10, warning = FALSE, message = FALSE}
library(knitr)
invisible(cleaned_speech <- cleaning_spliting_speech(single_speech, remove_stop_words = TRUE)) #Wrapping any object in invisible will prevent automatically printing it.
invisible(cleaned_speech_no_numbers <- removing_numbers_from_speech(cleaned_speech))
#
# get frequencies of all the words
get_word_freqyency <- function(df){
  df %>%
  count(date, word) %>%
  group_by(date) %>%
  mutate(p = n / sum(n))
}

  
invisible(word_frequency_df <- get_word_freqyency(cleaned_speech_no_numbers))

plot_frequency_changes <- function(df_frequency_table, keywords = c('biden', 'china')) {
  df_frequency_table %>%  
  filter(word %in% keywords) %>%
  ggplot(aes(x = date, y = p, color=word)) +
  geom_point() +
  geom_smooth(method = 'lm', se=FALSE, color='black', size=0.2)+
  geom_smooth(method = "loess")+
  labs(title = "Change of word frequency in Donald Trump's rallies in September 2020",
       x = "Rally date",
       y = "Percentage of words") +
  facet_wrap(~ word) +
  scale_x_date(labels = date_format("%d %b"),
  limits = c(as_date("2020-09-02"),
  as_date("2020-09-24"))) +
  scale_y_continuous(labels = scales::percent)+ # formating y axis to percentages
  theme_bw()+
  theme(legend.position = "none",
        plot.title = element_text(size=20),
        strip.text.x = element_text(size = 12, color = "white"),
        strip.background =element_rect(fill="orange"),
        strip.text = element_text(colour = 'black'))
}
# plotting
keywords <- c('biden','bernie','china','fake','america','people','job','country','nation','wall')
plot_frequency_changes(word_frequency_df, keywords)
```

# Discussion of the graph

In overall the word **people** is the word the highest frequency, as well as with the lowest central tendency, since
most of the points are more scattered and have greater distance from the regression lane, resulting high standard
errors. In the other hand the word **nation** seems to be the word with the less frequency. 

More analytically, we can assume that the reason the word people was used that much, is due to the
nature of public speeches, since the speaker is addressing to the crowed "people". The slope of the regression line is negative and close to zero.

Furthermore Donald Trump, appears that he spent a lot of his speech time dealing 
with his political opponent Joe Biden and China. The word **biden** is the next 
more frequent word. We can notice a moderate fall in the usage of the word after its 
peak on the 8th of September (about 1.5%), due to the slight negative slope of the curve. On 
this date ex-president Trump spent a lot of time attacking his opponent (https://edition.cnn.com/2020/09/08/politics/donald-trump-north-carolina-rally-fact-check/index.html). 
Also, the word **china** was used 206 times in total. According to the relevant graph, 
we can notice a moderate decrease in its overall usage, with a moderate variance, 
since the standard errors are close to the regression line. China was accused by Trump, in the majority of his speeches. He was mentioning that Chinese tech companies 
funnel American citizens personal data (Huawei, TikTok), as well as that China was 
incompetent to prevent the spread of Covid-19 to the rest of the world (https://www.politico.com/news/2020/09/11/trumps-tiktok-china-412053, https://slate.com/news-and-politics/2020/09/trump-woodward-book-panic-coronavirus-china.html ......)

We can notice also that Trump preferred the usage of the words **country** and **america**, compared to **nation**.  We can assume that country had the most appearances (country:255, America:202) because it might refer to any country in general, while America and nation are referring to America. The word country appears to have the lowest standard errors, indicating also a strong , as well as nation. On the other hand the word America seems to be overused Henderson speech on 13/09, and its points are more scattered.

Finally, is worth to mention that in the words we have chosen, the **wall** is the only with positive regression line slope, meaning that as the word frequency increases throught the passage of time. 
Also, the ex-President had not used this word until the 8th of September, however it gets more popular especially till the end of our search range which peaked at around 0.5%. Wall refers to the wall at the borders between the US and Mexico, which was the signature promise of President Donald Trump's 2016 election campaign.


### Most frequent words
```{r most_frequent_words, echo=FALSE}

table_of_word_frequencies <- function(cleaned_speech_df) {
  kable(
  cleaned_speech_df %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(20),
  col.names = c('Word', 'Frequency'), # Change column names
  align = "lr") # Specify column alignment
}
```


## 2.3  Plotting the Words with Highest tf-idf Value

```{r tf-idf, echo=FALSE, fig.height = 20, fig.width = 15, message=FALSE, warning=FALSE}
require(data.table)


make_bind_tf_idf <- function(df){
  df %>%
  count(location, word) %>%
  bind_tf_idf(word, location, n) %>%
  arrange(desc(tf_idf))
}

tf_idf_speech <- make_bind_tf_idf(cleaned_speech_no_numbers)

#d <- data.table(word_tf_idf_table, key='location')


make_plot_tf_idf <- function(df){
  df %>%
  group_by(location) %>%
  slice_max(tf_idf, n=10) %>%
  ggplot(aes(x=word, y=tf_idf, fill=location)) +
  labs(x = "Top 10 tf-idf words", y = "tf-idf index", 
       title = "Highest tf-idf words in Donald Trump's rallies in September 2020") +
  geom_col() +
  coord_flip() +
  facet_wrap(location~., scales ='free', ncol = 2, nrow = 5) +
  
  theme(legend.position="none",
          plot.title = element_text(size = 30),
          axis.title = element_text(size = 25), 
          axis.text = element_text(size = 20),
          strip.text = element_text(size = 20, colour = 'black'),
        strip.background =element_rect(fill="orange"))
}

make_plot_tf_idf(tf_idf_speech)
```

# Discussion of tf-idf

Tf-idf gives the weight of the word in an overall corpus. Words with high tf-idf, have a high term frequency but low document frequency (the do not appear a lot in an entire set of corpus). 
In our case, it can show if a word has meaning or relationship to a specific speech. As we can notice that names such as: **Jason**, **Bob**, **Dana**, **Colby** and **Mick** appear to have the highest tf-idf scores ranging from 0.007-0.010. 
This is not unusual since those names have a particular connection to their respective speech location/date. 

In the Bemidji Minnesota, Jason refers to Jason Lewis, former U.S. Representative for Minnesota's 2nd congressional district from 2017 to 2019 and member of the Republican Party.
The name Bob in the Ohio speech is refers to Bob Paduchik who was the Senior Advisor of Trumpâ€™s re-election campaign, who was quoted by Trump that they were going to win Ohio. Also, to Bob Latta U.S representative of Ohio and member of Republican party. 
In Henderson, the word Colby, refers to the UFC fighter Colby Covington, who is an outspoken supporter of the Republican Party and President Donald Trump, who joined him at the speech, while Dana, to Data White, President of the Ultimate Fighting Championship (UFC), another outspoken supporter. 

Furthermore, after checking the original speech text itself for all those names, it appears that there is a pattern in which Trump repeats himself when calling someoneâ€™s name:

- ***...We go to again win Ohio. I understand from Bob Paduchik, you know Bob? That we're going to win it by more than we did...***

- ***...Representative Bob Latta. Thank you, Bob. Great job. They like you, Bob. That's very good. Good job, Bob. Thank you very much...***

- ***...they don't fight like Colby. You know who Colby is. You're going to say hello to Colby. They don't fight like Colby...
 ...Let's say you'd had a fight and you happen to meet Colby Covington. You say, "What's your name?" And he said, "My name's Colby Covington." And the first time I saw Colby Covington...
 ...But I'd like to introduce Colby Covington. Great fighter. Great, great fighter. Incredible. He is a great fighter...***
 
According to (economist) when Trump needs to plan his next sentenceâ€”as everyone mustâ€”he often buys time by repeating himself. 
This reinforces the impression that he is supremely confident and that what heâ€™s saying is self-evident.

Also the word elite has a high score in Freeland, where trump was referring to the crowed as elite

Finally, we can notice the words with not that high score, such as tiktok, timber, cows, milk, hold a moderate score (0.02-0.03). The word tiktok appears to have a particular weight in Fayetteville, probably since one day before the speech (18 September), TikTok filed a lawsuit against Trump (TikTok v. Trump). The words timber, cows and milk show a relative weight in Mosinee,  Wisconsin. This can be explained by the fact the Wisconsin is leading state in dairy production (known as American Dairyland) as well as in agriculture industry and timber. 

## 2.4 Zipfâ€™s Law

```{r zipfs_law, echo=FALSE, message=FALSE}

cleaned_speech_with_stop_words <- cleaning_spliting_speech(single_speech, remove_stop_words = FALSE)

word_tf_idf_table_with_stop_words <- make_bind_tf_idf(cleaned_speech_with_stop_words)

```

```{r zipfs_law_graph, fig.height = 6, fig.width = 8, echo=FALSE, message=FALSE, warning=FALSE}

scaleFUN <- function(x){
  sprintf("%.4f", x) # (see sprintf documentation https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/sprintf)
}

zipf_law_df <-function(df){
  df %>%
  group_by(location) %>%
  arrange(desc(tf)) %>% 
  mutate(rank= row_number())
  
}

zipf_lm <- function(df) {
  df$log_rank <- log(df$rank, base=10)
  df$log_tf <- log(df$tf, base=10)
  lm_d <- lm(log_tf~log_rank, data = df)
  lm_d
}


plot_zipfs_law <-function(df){
  df %>%
  ggplot(aes(x=rank, y=tf, color=location)) +
  geom_line(alpha = 1, size=1) +
  geom_abline(intercept =-0.5871126, slope =-1, color = 'red', size = 1) + # draw a line with slope -1, for the theoretical line of zipfs law. Used to compare our regressions line slope
  geom_smooth(method = 'lm',  color = "black", se=FALSE, fullrange=FALSE) +
  scale_x_continuous(trans="log10", breaks=c(1,10,30,100,500,1000)) + # adding more scales in order to help us interpret the points where the curve have different trend
  scale_y_continuous(trans='log10', labels = scaleFUN) +  
  labs(title = "Zipf's Law for Donald Trump's Rallies Data",
      x = 'Rank',
      y = "Term frequency (tf)",
      color = "Location" )+
  theme(title = element_text(size= 13, face = 'bold'),
        axis.text = element_text(size = 9, color = "black"),
        axis.title = element_text(size = 10, color = "black")
       )
}

summary(zipf_lm(zipf_law_df(word_tf_idf_table_with_stop_words)))

p1 <- plot_zipfs_law(zipf_law_df(word_tf_idf_table_with_stop_words))
p1 
```

## Discussion

# Zipfs Law

The plot above shows, the application of Zipfâ€™s law in 10 Trump speeches.  The scales are in logarithms with base 10. Furthermore, the black line is the regression line of our plot, while the red line is the theoretical regression line of Zipfâ€™s law. According to Zipfâ€™s law, the frequency of any word is inversely proportional to its rank in the frequency table. 
From the graph we can notice that all the speeches follow almost the same trend, since all are concentrated together, especially for the ranks from 10 to 500.  This can indicate that almost the same vocabulary, with the same word frequencies was used in all the speeches. However, for the words with lower rank (500-1000), the lines can be distinguished. This means, that different words with greater meaning (word with lower frequencies tend to be words with higher meaning like nouns/verbs), were used in different locations. This is confirmed by the tf-idf graphs above (different words with high tf-idf appear on different locations).
We calculated the slope of our regression line in order to figure out the degree of deviation from Zipfâ€™s theoretical line (red line, slope = -1). In theory a Zipfâ€™s law curve will have a -1 slope, starting from the top left corner to the bottom right. In our case we notice that all the curves have some degree of deviation from this theory, especially for words with high rank. For words with rank 1 to 10, the curve is flatter, with a slope between -1 and zero. A flatter curve can indicate broader vocabulary for those ranks. However, the words in high ranks tend not to be that meaningful, mostly consisting of conjunctions. 
In the other hand we can notice that from rank 10 the speeches are almost sticked to their regression line. The regression line of the speeches (black line) has a slope of -1.11 indicating a sharper degree of change. That means the lower the rank of a word (greater x-value), the less term frequency it has, compared to the Zipfâ€™s law theory. So, a sharper slope (less than -1) can indicate a poorer vocabulary, for the words from ranks 10 and after (more meaningful words)


